{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wk4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqLglOIRW8IcWRdfsKwye8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minddong59/BigDataAnalysis2021/blob/main/wk4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADPtKXUN8pSt",
        "outputId": "17d54f98-489c-427a-80e1-eb8cd0f871d9"
      },
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!tar -xf spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!pip install findspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-1.4.2-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-1.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfstpRkd87I6"
      },
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fybzwfEB9et6"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuIzuuYD9gWx"
      },
      "source": [
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "sc = SparkContext('local')\n",
        "spark = SparkSession(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpZrG3y99lwm"
      },
      "source": [
        "import os\n",
        "myRdd=spark.sparkContext\\\n",
        "    .textFile(os.path.join(\"ds_bigdata_wiki.txt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL69L94n9rQw"
      },
      "source": [
        "wc=myRdd\\\n",
        "    .flatMap(lambda x:x.split())\\\n",
        "    .map(lambda x:(x,1))\\\n",
        "    .reduceByKey(lambda x,y:x+y)\\\n",
        "    .map(lambda x:(x[1],x[0]))\\\n",
        "    .sortByKey(False)\\\n",
        "    .map(lambda x:(x[1],x[0]))\\\n",
        "    .take(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z-4PlI29wlM",
        "outputId": "74d54e45-237b-4b01-e54e-3c774dcf3bf3"
      },
      "source": [
        "for e in wc:\n",
        "    k = e[0]\n",
        "    v = e[1]\n",
        "    print (f\"단어:{k}\\t\\t\\t빈도:{v}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어:데이터\t\t\t빈도:21\n",
            "단어:데이터를\t\t\t빈도:18\n",
            "단어:및\t\t\t빈도:15\n",
            "단어:빅\t\t\t빈도:14\n",
            "단어:등\t\t\t빈도:12\n",
            "단어:있다.\t\t\t빈도:9\n",
            "단어:수\t\t\t빈도:8\n",
            "단어:데이터의\t\t\t빈도:8\n",
            "단어:미국\t\t\t빈도:7\n",
            "단어:통해\t\t\t빈도:7\n",
            "단어:유권자\t\t\t빈도:6\n",
            "단어:선거\t\t\t빈도:6\n",
            "단어:대한\t\t\t빈도:6\n",
            "단어:빅데이터\t\t\t빈도:6\n",
            "단어:활용한\t\t\t빈도:5\n"
          ]
        }
      ]
    }
  ]
}